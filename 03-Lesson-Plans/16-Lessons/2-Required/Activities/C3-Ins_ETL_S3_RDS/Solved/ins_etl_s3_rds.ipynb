{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9-z0nsHH2B3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
    "# For example:\n",
    "# spark_version = 'spark-3.0.1'\n",
    "spark_version = 'spark-3.0.1'\n",
    "os.environ['SPARK_VERSION']=spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "!wget https://jdbc.postgresql.org/download/postgresql-42.2.9.jar\n",
    "\n",
    "# Start Spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"ETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.9.jar\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWGDjQeEIJzU"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkFiles\n",
    "# Load in user_data.csv from S3 into a DataFrame\n",
    "url = \"https://<bucket name>.s3.amazonaws.com/user_data.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "\n",
    "user_data_df = spark.read.option('header', 'true').csv(SparkFiles.get(\"user_data.csv\"), inferSchema=True, sep=',')\n",
    "user_data_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mdEBfSZeIOsv"
   },
   "outputs": [],
   "source": [
    "# Load in user_payment.csv from S3 into a DataFrame\n",
    "\n",
    "url = \"https://<bucket name>.s3.amazonaws.com/user_payment.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "\n",
    "user_payment_df = spark.read.option('header', 'true').csv(SparkFiles.get(\"user_payment.csv\"), inferSchema=True, sep=',')\n",
    "user_payment_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_3_ochKIQ_S"
   },
   "outputs": [],
   "source": [
    "# Join the two DataFrame\n",
    "joined_df= user_data_df.join(user_payment_df, on=\"username\", how=\"inner\")\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LfPqFWkTITfq"
   },
   "outputs": [],
   "source": [
    "# Drop null values\n",
    "dropna_df = joined_df.dropna()\n",
    "dropna_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TDkx3wQ9IZOh"
   },
   "outputs": [],
   "source": [
    "# Load in a sql function to use columns\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Filter for only columns with active users\n",
    "cleaned_df = dropna_df.filter(col(\"active_user\")  == True)\n",
    "cleaned_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HotpaJueIaag"
   },
   "outputs": [],
   "source": [
    "# Create user dataframe to match active_user table\n",
    "clean_user_df = cleaned_df.select([\"id\", \"first_name\", \"last_name\", \"username\"])\n",
    "clean_user_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SiFXloeYIeqa"
   },
   "outputs": [],
   "source": [
    "# Create user dataframe to match billing_info table\n",
    "clean_billing_df = cleaned_df.select([\"billing_id\", \"street_address\", \"state\", \"username\"])\n",
    "clean_billing_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0DHYdNoIgtw"
   },
   "outputs": [],
   "source": [
    "# Create user dataframe to match payment_info table\n",
    "clean_payment_df = cleaned_df.select([\"billing_id\", \"cc_encrypted\"])\n",
    "clean_payment_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWNGUSO-Ihq4"
   },
   "outputs": [],
   "source": [
    "# Configure settings for RDS\n",
    "mode = \"append\"\n",
    "jdbc_url=\"jdbc:postgresql://<endpoint>:5432/my_data_class_db\"\n",
    "config = {\"user\":\"root\", \n",
    "          \"password\": \"<password>\", \n",
    "          \"driver\":\"org.postgresql.Driver\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-hwlTkcIk7I"
   },
   "outputs": [],
   "source": [
    "# Append DataFrame to active_user table in RDS\n",
    "\n",
    "clean_user_df.write.jdbc(url=jdbc_url, table='active_user', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8ErcfX8Im2x"
   },
   "outputs": [],
   "source": [
    "# Write dataframe to billing_info table in RDS\n",
    "\n",
    "clean_billing_df.write.jdbc(url=jdbc_url, table='billing_info', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MN8GtAm6IooY"
   },
   "outputs": [],
   "source": [
    "# Write dataframe to payment_info table in RDS\n",
    "\n",
    "clean_payment_df.write.jdbc(url=jdbc_url, table='payment_info', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tYjvddlsEbBc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ins_etl_s3_rds.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
